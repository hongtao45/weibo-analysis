{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ–‡æœ¬é¢„å¤„ç† æµç¨‹ï¼ˆåŸæ¥çš„ä¸€æ ·ï¼Œä¸åšå˜åŒ–ï¼‰\n",
    "\n",
    "1. æ–‡æœ¬å»å™ª\n",
    "2. ä¸­æ–‡åˆ†è¯\n",
    "3. è¿‡æ»¤åœç”¨è¯\n",
    "4. è¯æ€§æ ‡æ³¨ ã€æ²¡æœ‰ç‰¹æ®Šéœ€æ±‚ï¼Œå’±ä»¬å°±ä¸ç”¨åšäº†\n",
    "5. æ–‡æœ¬å»é‡ ã€è€ƒè™‘å‘è¡¨çš„ç”¨æˆ·ï¼Œ**å®˜æ–¹å·**\n",
    "6. æ–‡æœ¬æ ‡è®°ã€æ‰‹åŠ¨æ•´ç†æ¨¡å‹è¾“å…¥æ•°æ®\n",
    "7. ç‰¹å¾è¯é€‰æ‹©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>å¾®åšæ­£æ–‡</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ã€é¢å¯¹æš´é›¨ï¼Œè¯·æ”¶å¥½è¿™ä»½#é¿é™©ç”Ÿå­˜æŒ‡å—#ã€‘#èœ€é»å¸¦ä½ æ¶¨å§¿åŠ¿#è¿‘æ—¥æ¥ï¼Œæ²³å—ä¸¤å°æ—¶æš´é›¨è®°å½•åˆè¢«åˆ·æ–°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#æ²³å—é«˜é€Ÿè·¯å†µ#æˆªè‡³2021å¹´9æœˆ9æ—¥,19:00ï¼Œç›®å‰çœå†…é«˜é€Ÿé€šè¡Œæƒ…å†µï¼š1ã€å› æ”¶è´¹ç«™ä¸´æ—¶æŠ¢...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>éƒ‘å·å¤§æš´é›¨ç¾å®³è¿™æ³¢ï¼Œä»Šå¤©å›æ¥åˆçœ‹åˆ°ä¸€äº¤é€šäº‹æ•…ï¼Œä¸€ä¸ªå¤§å”æ»¡èº«è¡€æ·‹æ·‹ååœ¨è½¦å‰ï¼Œå‰å‡ æ—¥æ­å·ç”µç“¶è½¦éª‘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ã€æš–å¿ƒï¼#äº¤è­¦æš´é›¨ä¸­æ‰§å‹¤é¢‘é¢‘è¢«è·¯äººé€ä¼#ã€‘6æœˆ10æ—¥17æ—¶è®¸ï¼Œæµ™æ±Ÿæ¸©å·æ³°é¡ºå¿ä¸€è·¯å£ä¸¥é‡æ‹¥å µï¼Œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ã€æ¹–å—å¤šåœ°è¿æš´é›¨ï¼è¿™äº›æ”¶è´¹ç«™ä»åœ¨ç®¡åˆ¶ä¸­ã€‘ä»Šæ—¥æ™šé—´ï¼Œæ¹–å—éƒ¨åˆ†åœ°åŒºçªé™æš´é›¨ï¼Œ905ä¸­å›½äº¤é€šå¹¿æ’­æ´¾...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                å¾®åšæ­£æ–‡\n",
       "0  ã€é¢å¯¹æš´é›¨ï¼Œè¯·æ”¶å¥½è¿™ä»½#é¿é™©ç”Ÿå­˜æŒ‡å—#ã€‘#èœ€é»å¸¦ä½ æ¶¨å§¿åŠ¿#è¿‘æ—¥æ¥ï¼Œæ²³å—ä¸¤å°æ—¶æš´é›¨è®°å½•åˆè¢«åˆ·æ–°...\n",
       "1  #æ²³å—é«˜é€Ÿè·¯å†µ#æˆªè‡³2021å¹´9æœˆ9æ—¥,19:00ï¼Œç›®å‰çœå†…é«˜é€Ÿé€šè¡Œæƒ…å†µï¼š1ã€å› æ”¶è´¹ç«™ä¸´æ—¶æŠ¢...\n",
       "2  éƒ‘å·å¤§æš´é›¨ç¾å®³è¿™æ³¢ï¼Œä»Šå¤©å›æ¥åˆçœ‹åˆ°ä¸€äº¤é€šäº‹æ•…ï¼Œä¸€ä¸ªå¤§å”æ»¡èº«è¡€æ·‹æ·‹ååœ¨è½¦å‰ï¼Œå‰å‡ æ—¥æ­å·ç”µç“¶è½¦éª‘...\n",
       "3  ã€æš–å¿ƒï¼#äº¤è­¦æš´é›¨ä¸­æ‰§å‹¤é¢‘é¢‘è¢«è·¯äººé€ä¼#ã€‘6æœˆ10æ—¥17æ—¶è®¸ï¼Œæµ™æ±Ÿæ¸©å·æ³°é¡ºå¿ä¸€è·¯å£ä¸¥é‡æ‹¥å µï¼Œ...\n",
       "4  ã€æ¹–å—å¤šåœ°è¿æš´é›¨ï¼è¿™äº›æ”¶è´¹ç«™ä»åœ¨ç®¡åˆ¶ä¸­ã€‘ä»Šæ—¥æ™šé—´ï¼Œæ¹–å—éƒ¨åˆ†åœ°åŒºçªé™æš´é›¨ï¼Œ905ä¸­å›½äº¤é€šå¹¿æ’­æ´¾..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¯¼å…¥åŒ…\n",
    "# å¯¼å…¥æ•°æ®\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import pkuseg\n",
    "import jieba\n",
    "\n",
    "data = pd.read_csv(\"../02Data/å®Œæ•´æ•°æ®_æš´é›¨_äº¤é€š.csv\")\n",
    "df = data.sample(n=500, replace=False, random_state=1) # æŒ‡å®šéšæœºç§å­ï¼Œä¿è¯éƒ½æ˜¯åŒä¸€ä¸ªæ•°æ®ç»„åˆ\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "tweets = df.loc[:99, ['å¾®åšæ­£æ–‡']].astype(\"string\") # å–100æ¡æ•°æ®å°±å¥½äº†\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   å¾®åšæ­£æ–‡    100 non-null    string\n",
      "dtypes: string(1)\n",
      "memory usage: 928.0 bytes\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 æ–‡æœ¬å»å™ª\n",
    "\n",
    "å¾®åšä¸­çš„ç‰¹æ®Šç¬¦å·ï¼Œå¯¹äºç®—æ³•çš„è®­ç»ƒæ¥è¯´ä¸å¤ªæœ‰åˆ©\n",
    "\n",
    "[Pythonæ­£åˆ™è¡¨è¾¾å¼æ¸…æ´—å¾®åšæ–‡æœ¬ç‰¹æ®Šç¬¦å·(ç½‘å€, @, è¡¨æƒ…ç¬¦ç­‰)](https://blog.csdn.net/blmoistawinde/article/details/103648044)\n",
    "\n",
    "[é™„ï¼šè¡¨è¾¾å¼å…¨é›†ï¼ˆæ­£åˆ™è¡¨è¾¾å¼æ‰‹å†Œï¼‰](https://blog.csdn.net/qq_33472765/article/details/80785441)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_noise(text):\n",
    "    \"\"\"\n",
    "    text å¾…å»å™ªçš„åŸå§‹æ–‡æœ¬\n",
    "    \"\"\"\n",
    "    text = text.replace(u'\\xa0', u' ')      # å»é™¤ \\xa0     ä¸é—´æ–­ç©ºç™½ç¬¦ \n",
    "    text = text.replace(u'\\u3000', u' ')    # å»é™¤ \\u3000   å…¨è§’çš„ç©ºç™½ç¬¦\n",
    "    \n",
    "    text = re.sub(r\"(å›å¤)?(//)?\\s*@\\S*?\\s*(ï¼Œ|:| |$)\", \"\", text)  # å»é™¤æ­£æ–‡ä¸­çš„@å’Œå›å¤/è½¬å‘ä¸­çš„ç”¨æˆ·å\n",
    "    text = re.sub(r\"\\[\\S+\\]\", \"\", text)     # å»é™¤è¡¨æƒ…ç¬¦å·\n",
    "    # text = re.sub(r\"#\\S+\\s*#\", \"\", text)    # å»é™¤è¯é¢˜å†…å®¹ â€œ#content#â€\n",
    "    # text = re.sub(r\"ã€\\S+\\s*ã€‘\", \"\", text)  # åˆ†ç±»æ ‡ç­¾â€œã€contentã€‘â€\n",
    "\n",
    "    URL_REGEX = re.compile(\n",
    "        r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?Â«Â»â€œâ€â€˜â€™]))',\n",
    "        re.IGNORECASE)\n",
    "    text = re.sub(URL_REGEX, \"\", text)      # å»é™¤ç½‘å€\n",
    "    \n",
    "    EMAIL_REGEX = re.compile(r\"[-a-z0-9_.]+@(?:[-a-z0-9]+\\.)+[a-z]{2,6}\", re.IGNORECASE)\n",
    "    text = re.sub(EMAIL_REGEX, \"\", text)    # å»é™¤é‚®ä»¶ \n",
    "    \n",
    "    text = text.replace(\"è½¬å‘å¾®åš\", \"\")      # å»é™¤æ— æ„ä¹‰çš„è¯è¯­\n",
    "    text = text.replace(\"ç½‘é¡µé“¾æ¥\", \"\")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)        # åˆå¹¶æ­£æ–‡ä¸­è¿‡å¤šçš„ç©ºæ ¼\n",
    "\n",
    "    text = re.sub(r\"\\d{2,4}å¹´|\\d{1,2}æœˆ|\\d{1,2}æ—¥|\\d{1,2}æ—¶|\\d{1,2}åˆ†| \\d{1,2}ç‚¹\", \"\", text) # å»é™¤ æ—¥æœŸ æ—¶é—´\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "    text = re.sub(r'[a-zA-Z]',\"\", text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŒ¹é…æ¬¡æ•°ï¼š1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # ä¹‹é—´çš„ä¸œè¥¿ä¹Ÿä¼šè¢«åˆ \n",
    "text1 = \"#æ²³å—é«˜é€Ÿè·¯å†µ#æˆªè‡³2021å¹´9æœˆ9æ—¥,19:00ï¼Œç›®å‰çœå†…é«˜é€Ÿé€šè¡Œæƒ…å†µé«˜é€ŸæœåŠ¡ç”µè¯12328æ±‚åŠ©ã€‚#æ²³å—æš´é›¨æ•‘æ´#\"\n",
    "\n",
    "text1, nu = re.subn(r\"(#)?\\S+\\s*(#)?\", \"\", text1)    # å»é™¤è¯é¢˜å†…å®¹ â€œ#content#â€\n",
    "print(\"åŒ¹é…æ¬¡æ•°ï¼š{}\".format(nu))\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>å¾®åšæ­£æ–‡</th>\n",
       "      <th>å»å™ª</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ã€é¢å¯¹æš´é›¨ï¼Œè¯·æ”¶å¥½è¿™ä»½#é¿é™©ç”Ÿå­˜æŒ‡å—#ã€‘#èœ€é»å¸¦ä½ æ¶¨å§¿åŠ¿#è¿‘æ—¥æ¥ï¼Œæ²³å—ä¸¤å°æ—¶æš´é›¨è®°å½•åˆè¢«åˆ·æ–°...</td>\n",
       "      <td>ã€é¢å¯¹æš´é›¨ï¼Œè¯·æ”¶å¥½è¿™ä»½#é¿é™©ç”Ÿå­˜æŒ‡å—#ã€‘#èœ€é»å¸¦ä½ æ¶¨å§¿åŠ¿#è¿‘æ—¥æ¥ï¼Œæ²³å—ä¸¤å°æ—¶æš´é›¨è®°å½•åˆè¢«åˆ·æ–°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#æ²³å—é«˜é€Ÿè·¯å†µ#æˆªè‡³2021å¹´9æœˆ9æ—¥,19:00ï¼Œç›®å‰çœå†…é«˜é€Ÿé€šè¡Œæƒ…å†µï¼š1ã€å› æ”¶è´¹ç«™ä¸´æ—¶æŠ¢...</td>\n",
       "      <td>#æ²³å—é«˜é€Ÿè·¯å†µ#æˆªè‡³,:ï¼Œç›®å‰çœå†…é«˜é€Ÿé€šè¡Œæƒ…å†µï¼šã€å› æ”¶è´¹ç«™ä¸´æ—¶æŠ¢ä¿®æ–½å·¥ï¼Œèå®é«˜é€Ÿæ–°ä¹¡ä¸œç«™ï¼ˆåŒ—...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>éƒ‘å·å¤§æš´é›¨ç¾å®³è¿™æ³¢ï¼Œä»Šå¤©å›æ¥åˆçœ‹åˆ°ä¸€äº¤é€šäº‹æ•…ï¼Œä¸€ä¸ªå¤§å”æ»¡èº«è¡€æ·‹æ·‹ååœ¨è½¦å‰ï¼Œå‰å‡ æ—¥æ­å·ç”µç“¶è½¦éª‘...</td>\n",
       "      <td>éƒ‘å·å¤§æš´é›¨ç¾å®³è¿™æ³¢ï¼Œä»Šå¤©å›æ¥åˆçœ‹åˆ°ä¸€äº¤é€šäº‹æ•…ï¼Œä¸€ä¸ªå¤§å”æ»¡èº«è¡€æ·‹æ·‹ååœ¨è½¦å‰ï¼Œå‰å‡ æ—¥æ­å·ç”µç“¶è½¦éª‘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ã€æš–å¿ƒï¼#äº¤è­¦æš´é›¨ä¸­æ‰§å‹¤é¢‘é¢‘è¢«è·¯äººé€ä¼#ã€‘6æœˆ10æ—¥17æ—¶è®¸ï¼Œæµ™æ±Ÿæ¸©å·æ³°é¡ºå¿ä¸€è·¯å£ä¸¥é‡æ‹¥å µï¼Œ...</td>\n",
       "      <td>ã€æš–å¿ƒï¼#äº¤è­¦æš´é›¨ä¸­æ‰§å‹¤é¢‘é¢‘è¢«è·¯äººé€ä¼#ã€‘è®¸ï¼Œæµ™æ±Ÿæ¸©å·æ³°é¡ºå¿ä¸€è·¯å£ä¸¥é‡æ‹¥å µï¼Œä¸€åäº¤è­¦åœ¨ç–å¯¼äº¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ã€æ¹–å—å¤šåœ°è¿æš´é›¨ï¼è¿™äº›æ”¶è´¹ç«™ä»åœ¨ç®¡åˆ¶ä¸­ã€‘ä»Šæ—¥æ™šé—´ï¼Œæ¹–å—éƒ¨åˆ†åœ°åŒºçªé™æš´é›¨ï¼Œ905ä¸­å›½äº¤é€šå¹¿æ’­æ´¾...</td>\n",
       "      <td>ã€æ¹–å—å¤šåœ°è¿æš´é›¨ï¼è¿™äº›æ”¶è´¹ç«™ä»åœ¨ç®¡åˆ¶ä¸­ã€‘ä»Šæ—¥æ™šé—´ï¼Œæ¹–å—éƒ¨åˆ†åœ°åŒºçªé™æš´é›¨ï¼Œä¸­å›½äº¤é€šå¹¿æ’­æ´¾å‡ºå››è·¯...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                å¾®åšæ­£æ–‡  \\\n",
       "0  ã€é¢å¯¹æš´é›¨ï¼Œè¯·æ”¶å¥½è¿™ä»½#é¿é™©ç”Ÿå­˜æŒ‡å—#ã€‘#èœ€é»å¸¦ä½ æ¶¨å§¿åŠ¿#è¿‘æ—¥æ¥ï¼Œæ²³å—ä¸¤å°æ—¶æš´é›¨è®°å½•åˆè¢«åˆ·æ–°...   \n",
       "1  #æ²³å—é«˜é€Ÿè·¯å†µ#æˆªè‡³2021å¹´9æœˆ9æ—¥,19:00ï¼Œç›®å‰çœå†…é«˜é€Ÿé€šè¡Œæƒ…å†µï¼š1ã€å› æ”¶è´¹ç«™ä¸´æ—¶æŠ¢...   \n",
       "2  éƒ‘å·å¤§æš´é›¨ç¾å®³è¿™æ³¢ï¼Œä»Šå¤©å›æ¥åˆçœ‹åˆ°ä¸€äº¤é€šäº‹æ•…ï¼Œä¸€ä¸ªå¤§å”æ»¡èº«è¡€æ·‹æ·‹ååœ¨è½¦å‰ï¼Œå‰å‡ æ—¥æ­å·ç”µç“¶è½¦éª‘...   \n",
       "3  ã€æš–å¿ƒï¼#äº¤è­¦æš´é›¨ä¸­æ‰§å‹¤é¢‘é¢‘è¢«è·¯äººé€ä¼#ã€‘6æœˆ10æ—¥17æ—¶è®¸ï¼Œæµ™æ±Ÿæ¸©å·æ³°é¡ºå¿ä¸€è·¯å£ä¸¥é‡æ‹¥å µï¼Œ...   \n",
       "4  ã€æ¹–å—å¤šåœ°è¿æš´é›¨ï¼è¿™äº›æ”¶è´¹ç«™ä»åœ¨ç®¡åˆ¶ä¸­ã€‘ä»Šæ—¥æ™šé—´ï¼Œæ¹–å—éƒ¨åˆ†åœ°åŒºçªé™æš´é›¨ï¼Œ905ä¸­å›½äº¤é€šå¹¿æ’­æ´¾...   \n",
       "\n",
       "                                                  å»å™ª  \n",
       "0  ã€é¢å¯¹æš´é›¨ï¼Œè¯·æ”¶å¥½è¿™ä»½#é¿é™©ç”Ÿå­˜æŒ‡å—#ã€‘#èœ€é»å¸¦ä½ æ¶¨å§¿åŠ¿#è¿‘æ—¥æ¥ï¼Œæ²³å—ä¸¤å°æ—¶æš´é›¨è®°å½•åˆè¢«åˆ·æ–°...  \n",
       "1  #æ²³å—é«˜é€Ÿè·¯å†µ#æˆªè‡³,:ï¼Œç›®å‰çœå†…é«˜é€Ÿé€šè¡Œæƒ…å†µï¼šã€å› æ”¶è´¹ç«™ä¸´æ—¶æŠ¢ä¿®æ–½å·¥ï¼Œèå®é«˜é€Ÿæ–°ä¹¡ä¸œç«™ï¼ˆåŒ—...  \n",
       "2  éƒ‘å·å¤§æš´é›¨ç¾å®³è¿™æ³¢ï¼Œä»Šå¤©å›æ¥åˆçœ‹åˆ°ä¸€äº¤é€šäº‹æ•…ï¼Œä¸€ä¸ªå¤§å”æ»¡èº«è¡€æ·‹æ·‹ååœ¨è½¦å‰ï¼Œå‰å‡ æ—¥æ­å·ç”µç“¶è½¦éª‘...  \n",
       "3  ã€æš–å¿ƒï¼#äº¤è­¦æš´é›¨ä¸­æ‰§å‹¤é¢‘é¢‘è¢«è·¯äººé€ä¼#ã€‘è®¸ï¼Œæµ™æ±Ÿæ¸©å·æ³°é¡ºå¿ä¸€è·¯å£ä¸¥é‡æ‹¥å µï¼Œä¸€åäº¤è­¦åœ¨ç–å¯¼äº¤...  \n",
       "4  ã€æ¹–å—å¤šåœ°è¿æš´é›¨ï¼è¿™äº›æ”¶è´¹ç«™ä»åœ¨ç®¡åˆ¶ä¸­ã€‘ä»Šæ—¥æ™šé—´ï¼Œæ¹–å—éƒ¨åˆ†åœ°åŒºçªé™æš´é›¨ï¼Œä¸­å›½äº¤é€šå¹¿æ’­æ´¾å‡ºå››è·¯...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"å»å™ª\"] = tweets[\"å¾®åšæ­£æ–‡\"].apply(clear_noise).astype(\"string\")\n",
    "tweets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   å¾®åšæ­£æ–‡    100 non-null    string\n",
      " 1   å»å™ª      100 non-null    string\n",
      "dtypes: string(2)\n",
      "memory usage: 1.7 KB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 ä¸­æ–‡åˆ†è¯\n",
    "\n",
    "[pkuseg: ä¸€ä¸ªå¤šé¢†åŸŸä¸­æ–‡åˆ†è¯å·¥å…·åŒ…](https://github.com/lancopku/pkuseg-python)\n",
    "\n",
    "[jieba: ç»“å·´ä¸­æ–‡åˆ†è¯](https://github.com/fxsjy/jieba)\n",
    "\n",
    "ä»githubä¸‹è½½çš„ç”¨æˆ·åˆ™éœ€è¦è‡ªå·±ä¸‹è½½å¯¹åº”çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è®¾ç½®model_nameå­—æ®µä¸ºé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ã€‚é¢„è®­ç»ƒæ¨¡å‹å¯ä»¥åœ¨[release](https://github.com/lancopku/pkuseg-python/releases)éƒ¨åˆ†ä¸‹è½½ã€‚ä»¥ä¸‹æ˜¯å¯¹é¢„è®­ç»ƒæ¨¡å‹çš„è¯´æ˜ï¼š\n",
    "\n",
    "- **news**: åœ¨MSRAï¼ˆæ–°é—»è¯­æ–™ï¼‰ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚ã€å¯ä»¥æµ‹è¯•\n",
    "- **web**: åœ¨å¾®åšï¼ˆç½‘ç»œæ–‡æœ¬è¯­æ–™ï¼‰ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚ã€å¯ä»¥æµ‹è¯•\n",
    "- **medicine**: åœ¨åŒ»è¯é¢†åŸŸä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚\n",
    "- **tourism**: åœ¨æ—…æ¸¸é¢†åŸŸä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚\n",
    "- **mixed**: æ··åˆæ•°æ®é›†è®­ç»ƒçš„é€šç”¨æ¨¡å‹ã€‚éšpipåŒ…é™„å¸¦çš„æ˜¯æ­¤æ¨¡å‹ã€‚ã€å¯ä»¥æµ‹è¯•\n",
    "\n",
    "æˆ‘ä»¬è¿˜é€šè¿‡é¢†åŸŸè‡ªé€‚åº”çš„æ–¹æ³•ï¼Œåˆ©ç”¨ç»´åŸºç™¾ç§‘çš„æœªæ ‡æ³¨æ•°æ®å®ç°äº†å‡ ä¸ªç»†é¢†åŸŸé¢„è®­ç»ƒæ¨¡å‹çš„è‡ªåŠ¨æ„å»ºä»¥åŠé€šç”¨æ¨¡å‹çš„ä¼˜åŒ–ï¼Œè¿™äº›æ¨¡å‹ç›®å‰ä»…å¯ä»¥åœ¨releaseä¸­ä¸‹è½½ï¼š\n",
    "\n",
    "- **art**: åœ¨è‰ºæœ¯ä¸æ–‡åŒ–é¢†åŸŸä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚\n",
    "- **entertainment**: åœ¨å¨±ä¹ä¸ä½“è‚²é¢†åŸŸä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚\n",
    "- **science**: åœ¨ç§‘å­¦é¢†åŸŸä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚\n",
    "- **default_v2**: ä½¿ç”¨é¢†åŸŸè‡ªé€‚åº”æ–¹æ³•å¾—åˆ°çš„ä¼˜åŒ–åçš„é€šç”¨æ¨¡å‹ï¼Œç›¸è¾ƒäºé»˜è®¤æ¨¡å‹è§„æ¨¡æ›´å¤§ï¼Œä½†æ³›åŒ–æ€§èƒ½æ›´å¥½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['æˆ‘', 'çˆ±', 'åŒ—äº¬', 'å¤©å®‰é—¨']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# jiebaåˆ†è¯\n",
    "\n",
    "def jieba_segment(str, use_paddle=True):\n",
    "    \"\"\"\n",
    "    jiebaåˆ†è¯:\n",
    "    str         : å¾…åˆ†è¯çš„æ–‡æœ¬\n",
    "    use_paddle  : æ˜¯å¦ä½¿ç”¨paddleæ¨¡å‹\n",
    "    \"\"\"\n",
    "    word_list = jieba.cut(str, use_paddle=use_paddle)   # åˆ†è¯åè¿”å›ä¸€ä¸ªåˆ—è¡¨  jieba.cut(ï¼‰   è¿”å›çš„æ˜¯ä¸€ä¸ªè¿­ä»£å™¨\n",
    "    res = list(word_list)\n",
    "   \n",
    "    return res\n",
    "\n",
    "#! æµ‹è¯•\n",
    "jieba_segment('æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['æˆ‘', 'çˆ±', 'åŒ—äº¬', 'å¤©å®‰é—¨']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pkuseg åˆ†è¯ \n",
    "\n",
    "def pkuseg_segment(str, m_name=\"web\", u_dict=\"default\"):\n",
    "    \"\"\"\n",
    "    pkusegåˆ†è¯:\n",
    "    str     :å¾…åˆ†è¯çš„æ–‡æœ¬\n",
    "    m_name  : é€‰æ‹©ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹\n",
    "    u_dict  : ç”¨æˆ·è‡ªå®šä¹‰çš„åˆ†è¯è®¾ç½®ç”¨æˆ·è¯å…¸ã€‚\n",
    "    \"\"\"\n",
    "    # m_name= \"news\"\n",
    "    # m_name= \"mixed\"\n",
    "    # p_tag= True # æ˜¯å¦åŒ…å«è¯æ€§\n",
    "    seg = pkuseg.pkuseg(model_name=m_name, user_dict=u_dict)           # ä»¥é»˜è®¤é…ç½®åŠ è½½æ¨¡å‹    \n",
    "    res = seg.cut(str)  # è¿›è¡Œåˆ†è¯\n",
    "   \n",
    "    return res\n",
    "\n",
    "#! æµ‹è¯•\n",
    "pkuseg_segment('æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets[\"jieba\"] = tweets[\"å»å™ª\"].apply(jieba_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! æ—¶é—´æ¯”è¾ƒ3minï¼Œè½»æ˜“ä¸å°è¯•\n",
    "tweets[\"pkuseg\"] = tweets[\"å»å™ª\"].apply(pkuseg_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   å¾®åšæ­£æ–‡    100 non-null    string\n",
      " 1   å»å™ª      100 non-null    string\n",
      " 2   jieba   100 non-null    object\n",
      " 3   pkuseg  100 non-null    object\n",
      "dtypes: object(2), string(2)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.to_excel(\"../02Data/jieba_pkuseg.xlsx\")\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 è¿‡æ»¤åœç”¨è¯\n",
    "\n",
    "- æ”¯æŒæ–°å¢åœç”¨è¯åº“\n",
    "- è€ƒè™‘è¯æ€§æ ‡å‡†æ—¶çš„å»åœç”¨è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['è¾½å®', 'å¤©æ°”', 'æˆ‘çœ', 'å¤§éƒ¨åˆ†', 'åœ°åŒº', 'å‡ºç°', 'å¼ºå¯¹æµ', 'å¤©æ°”', 'æ³¨æ„', 'é˜²èŒƒ', 'é›·é›¨å¤§é£', 'çŸ­æ—¶', 'å¼ºé™æ°´', 'å½±å“', 'æ‘˜è¦', 'é¢„è®¡', 'æˆ‘çœ', 'å¤§éƒ¨åˆ†', 'åœ°åŒº', 'å‡ºç°', 'é›·ç”µ', 'å¤§é£', 'çŸ­æ—¶', 'å¼ºé™æ°´', 'å†°é›¹', 'å¼ºå¯¹æµ', 'å¤©æ°”', 'è¥¿éƒ¨', 'åŒ—éƒ¨', 'åœ°åŒº', 'æœ€å¤§', 'ç¬æ—¶', 'é£åŠ›', 'å±€éƒ¨', 'å¯è¾¾çº§', 'ä»¥ä¸Š', 'è¥¿éƒ¨', 'ä¸ªåˆ«', 'ä¹¡é•‡', 'è¡—é“', 'é™é›¨é‡', 'æ¯«ç±³', 'æœ€å¤§', 'å°æ—¶', 'é™é›¨é‡', 'æ¯«ç±³', 'è¥¿éƒ¨', 'ä¸œå—éƒ¨', 'åœ°åŒº', 'å¼ºå¯¹æµ', 'å¤©æ°”', 'ä¸»è¦', 'å½±å“', 'æ—¶æ®µ', 'ä¸­åˆ', 'å¤œé—´', 'åŒ—éƒ¨', 'åœ°åŒº', 'å¤œé—´', 'æ³¨æ„', 'é˜²èŒƒ', 'å¼ºå¯¹æµ', 'å¤©æ°”', 'å¸¦æ¥', 'ä¸åˆ©', 'å½±å“', 'æ°”è±¡æ¡ä»¶', 'åˆ†æ', 'è’™å¤', 'ä¸­éƒ¨', 'é«˜ç©ºæ§½', 'ä¸œç§»', 'è¿‡ç¨‹', 'åŠ æ·±', 'é«˜ç©º', 'å†·æ¶¡', 'ä½å±‚', 'åå—', 'æ€¥æµ', 'å»ºç«‹', 'è¾½å®', 'è¾“é€', 'æš–æ¹¿', 'ç©ºæ°”', 'æ•´å±‚', 'å¤§æ°”', 'é™æ°´é‡', 'æ°´æ±½', 'æ¡ä»¶', 'å……è¶³', 'æœ‰åˆ©äº', 'å‡ºç°', 'çŸ­æ—¶', 'å¼ºé™æ°´', 'è¥¿éƒ¨', 'åŒ—éƒ¨', 'åœ°åŒº', 'ç¨³å®š', 'èƒ½é‡', 'å……åˆ†', 'ç§¯ç´¯', 'å¯¹æµ', 'æœ‰æ•ˆ', 'é€æ¸', 'å¢å¼º', 'é…åˆ', 'å‚ç›´', 'åˆ‡å˜', 'æœ‰åˆ©äº', 'å¯¹æµ', 'ç³»ç»Ÿ', 'å‘å±•', 'å‡ºç°', 'å¤§é£', 'å†°é›¹', 'å¼ºå¯¹æµ', 'å¤©æ°”', 'å…¥æµ·', 'æ°”æ—‹', 'å½±å“', 'ç™½å¤©', 'å¤œé—´', 'æˆ‘çœ', 'æµ·åŒº', 'å‡ºç°', 'å¤§é£', 'å¤©æ°”', 'å¼ºå¯¹æµ', 'å¤©æ°”é¢„æŠ¥', 'æˆ‘çœ', 'å¤§éƒ¨åˆ†', 'åœ°åŒº', 'å¼ºå¯¹æµ', 'å¤©æ°”', 'é¢„è®¡', 'é”¦å·', 'é˜œæ–°', 'é“å²­', 'æœé˜³', 'ç›˜é”¦', 'è‘«èŠ¦å²›', 'åœ°åŒº', 'åº·å¹³', 'æ³•åº“', 'æ–°æ°‘', 'å°å®‰', 'é›·ç”µ', 'å¤§é£', 'çŸ­æ—¶', 'å¼ºé™æ°´', 'å†°é›¹', 'å¼ºå¯¹æµ', 'å¤©æ°”', 'æœ€å¤§', 'ç¬æ—¶', 'é£åŠ›', 'å±€éƒ¨', 'å¯è¾¾çº§', 'ä»¥ä¸Š', 'æœ€å¤§', 'å°æ—¶', 'é™é›¨é‡', 'æ¯«ç±³', 'ä¸¹ä¸œ', 'åœ°åŒº', 'å¤§è¿å¸‚', 'æ—…é¡º', 'é‡‘æ™®', 'æ–°åŒº', 'æ™®å…°åº—', 'é•¿æµ·', 'åº„æ²³', 'å²«å²©', 'é›·ç”µ', 'çŸ­æ—¶', 'å¼ºé™æ°´', 'æœ€å¤§', 'å°æ—¶', 'é™é›¨é‡', 'æ¯«ç±³', 'åœ°åŒº', 'é›·ç”µ', 'è¥¿éƒ¨', 'ä¸œå—éƒ¨', 'åœ°åŒº', 'å¼ºå¯¹æµ', 'å¤©æ°”', 'ä¸»è¦', 'å½±å“', 'æ—¶æ®µ', 'ä¸­åˆ', 'å¤œé—´', 'åŒ—éƒ¨', 'åœ°åŒº', 'å¤œé—´', 'ç™½å¤©', 'å¤œé—´', 'æµ·åŒº', 'ä¸œé£', 'ä¸œåŒ—é£', 'é˜µé£', 'å½±å“', 'å»ºè®®', 'å¼ºå¯¹æµ', 'å¤©æ°”', 'çªå‘æ€§', 'å±€åœ°', 'æ€§å¼º', 'æé†’', 'å…¬ä¼—', 'ç›¸å…³', 'éƒ¨é—¨', 'å…³æ³¨', 'æ°”è±¡éƒ¨é—¨', 'æ»šåŠ¨', 'æ›´æ–°', 'å‘å¸ƒ', 'é¢„æŠ¥', 'é¢„è­¦', 'ä¿¡æ¯', 'ç»„ç»‡', 'åšå¥½', 'é˜²èŒƒ', 'åº”å¯¹', 'å·¥ä½œ', 'å»ºè®®', 'æˆ‘çœ', 'å‡ºç°', 'å¼ºé™é›¨', 'é¢„è®¡', 'è¥¿éƒ¨', 'åœ°åŒº', 'å‡ºç°', 'å¼ºé™é›¨', 'é™é›¨', 'å åŠ ', 'ä½œç”¨', 'å½±å“', 'å‘ç”Ÿ', 'å±±æ´ª', 'æ»‘å¡', 'æ³¥çŸ³æµ', 'ä¸­å°', 'æ²³æµ', 'æ´ªæ°´', 'å¯èƒ½æ€§', 'å¢å¤§', 'åšå¥½', 'æµåŸŸ', 'æ°´åº“', 'å°åŸé•‡', 'é˜²æ±›', 'é‡ç‚¹', 'äººç¾¤', 'é¿é™©', 'è½¬ç§»', 'å·¥ä½œ', 'åŠ å¼º', 'åœ°è´¨ç¾å®³', 'éšæ‚£', 'å±±åŒº', 'åŸé•‡', 'å­¦æ ¡', 'åŒ»é™¢', 'é‡è¦', 'å·¥ç¨‹', 'è®¾æ–½', 'ç…¤çŸ¿', 'å°¾çŸ¿åº“', 'ç›‘æµ‹', 'é˜²èŒƒ', 'å½“æœ‰', 'é›·ç”µ', 'å¤©æ°”', 'å‘ç”Ÿ', 'å°½é‡é¿å…', 'æˆ·å¤–æ´»åŠ¨', 'å®¤å¤–', 'äººå‘˜', 'ä¸è¦', 'æ ‘ä¸‹', 'ç”µæ†', 'å¡”åŠ', 'é¿é›¨', 'é˜²èŒƒ', 'é›·ç”µ', 'å¯èƒ½', 'é€ æˆ', 'äººå‘˜ä¼¤äº¡', 'è®¾å¤‡', 'æŸå¤±', 'å…³æ³¨', 'èˆªç©ºè¿è¾“', 'å½±å“', 'åŠ å¼º', 'å›½çœ', 'å¹²é“', 'åŒºå¿', 'ä¹¡é•‡', 'é“è·¯', 'è¿‡æ²³', 'æ¡¥æ¢', 'éš§é“', 'æ¶µæ´', 'åŸå¸‚', 'ä½æ´¼', 'è·¯æ®µ', 'ç®¡æ§', 'é˜²èŒƒ', 'çŸ­æ—¶', 'å¼ºé™æ°´', 'é€ æˆ', 'åŸå¸‚', 'å†…æ¶', 'äº¤é€š', 'å‡ºè¡Œ', 'å½±å“', 'ç¬æ—¶', 'é£åŠ›', 'è¾ƒå¤§', 'æ³¨æ„', 'é˜²èŒƒ', 'å¯èƒ½', 'é€ æˆ', 'æ­å»º', 'å€’å¡Œ', 'é«˜ç©ºä½œä¸š', 'æ°´åŸŸ', 'ä½œä¸š', 'è®¾æ–½', 'å†œä¸š', 'æµ·ä¸Š', 'èˆªè¿', 'å½±å“', 'æ£€æŸ¥', 'åŠ å›º', 'å¡”åŠ', 'è„šæ‰‹æ¶', 'æˆ·å¤–', 'å¹¿å‘Šç‰Œ', 'å…¬ä¼—', 'å¤–å‡º', 'ä¸è¦', 'å¹¿å‘Šç‰Œ', 'ä¸´æ—¶', 'æ­å»º', 'ç‰©ç­‰', 'ä¸‹é¢', 'åœç•™', 'é˜²æ­¢', 'å¤§é£', 'å¼•å‘', 'å€’å¡Œ', 'å ç‰©', 'è§¦ç”µ', 'äº‹ä»¶', 'æµ·ä¸Š', 'èˆªè¿', 'éœ€æ³¨æ„', 'å®‰å…¨', 'å¦¥å–„', 'ä¿æŠ¤', 'æ˜“å—', 'å†°é›¹', 'è¢­å‡»', 'æ±½è½¦', 'å®¤å¤–', 'ç‰©å“', 'è®¾å¤‡', 'é˜²èŒƒ', 'å†°é›¹', 'å†œä½œç‰©', 'æœè”¬', 'å†œä¸š', 'è®¾æ–½', 'é€ æˆ', 'ä¸åˆ©', 'å½±å“', 'æå‰', 'é©±èµ¶', 'å®¶ç¦½', 'ç‰²ç•œ', 'è¿›å…¥', 'é¡¶æ£š', 'åœºæ‰€', 'åœŸå£¤', 'é¥±å’Œ', 'åœ°åŒº', 'æå‰', 'ç–é€š', 'æ²Ÿæ¸ ', 'åŠæ—¶', 'æ’é™¤', 'ç”°é—´', 'ç§¯æ°´', 'é˜²èŒƒ', 'å¼ºé™é›¨', 'å¼•å‘', 'å†œç”°', 'æ¸æ¶', 'è¾½å®', 'è¾½å®', 'æš´é›¨', 'è¾½å®', 'èº«è¾¹', 'è¾½å®', 'ç”Ÿæ´»', 'å¤©æ°”', 'å¼ºå¯¹æµ', 'å¤©æ°”']\n"
     ]
    }
   ],
   "source": [
    "def clear_stopword(word_ls, stopword_file, postag=False, user_file=\"../05stopwords/user_stopwords.txt\"):\n",
    "    \"\"\"\n",
    "    word_ls         :å¾…å»åœç”¨è¯çš„è¯æ±‡åˆ—è¡¨ã€word æˆ–è€…æ˜¯ tuple(word, postag) ç»„æˆçš„list\n",
    "    stopword_file   :é€‰æ‹©ä½¿ç”¨çš„åœç”¨è¯åº“\n",
    "    user_file       :ç”¨æˆ·è‡ªå®šä¹‰çš„åœç”¨è¯åº“\n",
    "    postag          :æ˜¯å¦æœ‰è¯æ€§æ ‡æ³¨\n",
    "    \"\"\"\n",
    "    with open(stopword_file, 'r', encoding='utf-8') as f1, open(user_file, 'r' , encoding='utf-8') as f2:    # \n",
    "        \n",
    "        stopword_ls = [word.strip('\\n') for word in f1.readlines()] # é»˜è®¤è¯åº“\n",
    "        user_ls = [word.strip('\\n') for word in f2.readlines()]     # è‡ªå®šä¹‰è¯åº“\n",
    "\n",
    "        stopword_ls.extend(user_ls)\n",
    "        \n",
    "        res = []\n",
    "        if postag: # æœ‰è¯æ€§æ ‡æ³¨\n",
    "            for word_tag in word_ls:\n",
    "                w, t = word_tag\n",
    "                if w not in stopword_ls and len(w) > 1: # ä»…ä¿ç•™2ä¸ªå­—ç¬¦åŠä»¥ä¸Šçš„è¯\n",
    "                    res.append((w, t))\n",
    "        else:\n",
    "            for w in word_ls:\n",
    "                if w not in stopword_ls and len(w) > 1: # ä»…ä¿ç•™2ä¸ªå­—ç¬¦åŠä»¥ä¸Šçš„è¯\n",
    "                    res.append(w)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "#! æµ‹è¯•\n",
    "word_ls = tweets[\"jieba\"][9]\n",
    "stopword_file = \"../05stopwords/hit_stopwords.txt\"\n",
    "postag = False\n",
    "user_file = \"../05stopwords/user_stopwords.txt\"\n",
    "\n",
    "res = clear_stopword(word_ls, stopword_file, postag, user_file)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_file = \"../05stopwords/hit_stopwords.txt\"\n",
    "postag = False\n",
    "user_file = \"../05stopwords/user_stopwords.txt\"\n",
    "\n",
    "tweets[\"jieba_stop\"] = tweets[\"jieba\"].apply(clear_stopword, args=[stopword_file, postag, user_file])\n",
    "tweets[\"pkuseg_stop\"] = tweets[\"pkuseg\"].apply(clear_stopword, args=[stopword_file, postag, user_file])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   å¾®åšæ­£æ–‡         100 non-null    string\n",
      " 1   å»å™ª           100 non-null    string\n",
      " 2   jieba        100 non-null    object\n",
      " 3   pkuseg       100 non-null    object\n",
      " 4   jieba_stop   100 non-null    object\n",
      " 5   pkuseg_stop  100 non-null    object\n",
      "dtypes: object(4), string(2)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.to_excel(\"../02Data/jieba_pkuseg.xlsx\")\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æµ‹è¯•ç‰¹æ®Šç¬¦å·çš„é•¿åº¦\n",
    "\n",
    "a = 'âš ï¸'\n",
    "b = 'ğŸŒªï¸'\n",
    "c = 'ğŸŒ¬'\n",
    "len(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 åˆ†è¯+è¯æ€§æ ‡æ³¨ \n",
    "\n",
    "\n",
    "[pkuseg: ä¸€ä¸ªå¤šé¢†åŸŸä¸­æ–‡åˆ†è¯å·¥å…·åŒ…](https://github.com/lancopku/pkuseg-python)\n",
    "\n",
    "[jieba: ç»“å·´ä¸­æ–‡åˆ†è¯](https://github.com/fxsjy/jieba)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('æˆ‘', 'r'), ('çˆ±', 'v'), ('åŒ—äº¬', 'ns'), ('å¤©å®‰é—¨', 'ns')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jieba è¯æ€§æ ‡æ³¨ï¼ˆpart-of-speech taggingï¼‰\n",
    "\n",
    "def jieba_postag(str, use_paddle=True):\n",
    "    \"\"\"\n",
    "    jiebaåˆ†è¯:\n",
    "    str         : å¾…åˆ†è¯çš„æ–‡æœ¬\n",
    "    use_paddle  : æ˜¯å¦ä½¿ç”¨paddleæ¨¡å‹\n",
    "    \"\"\"\n",
    "    import jieba.posseg as pseg\n",
    "    word_tag_ls = pseg.lcut(str, use_paddle=use_paddle)\n",
    "    \n",
    "    res = [] # å°†è¯è¯­ä¸è¯æ€§ä»pairå¯¹è±¡è½¬æ¢ä¸º å…ƒç»„ï¼Œæ–¹ä¾¿ç´¢å¼•\n",
    "    for w_t in word_tag_ls:\n",
    "        w, t = w_t\n",
    "        res.append((w, t))\n",
    "    return res\n",
    "\n",
    "\n",
    "#! æµ‹è¯•\n",
    "res = jieba_postag('æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('æˆ‘', 'r'), ('çˆ±', 'v'), ('åŒ—äº¬', 'ns'), ('å¤©å®‰é—¨', 'ns')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pkuseg è¯æ€§æ ‡æ³¨ï¼ˆpart-of-speech taggingï¼‰\n",
    "# pkuseg åˆ†è¯ \n",
    "\n",
    "def pkuseg_postag(str, m_name=\"web\", u_dict=\"default\", p_tag=True):\n",
    "    \"\"\"\n",
    "    pkusegåˆ†è¯:\n",
    "    str     :å¾…åˆ†è¯çš„æ–‡æœ¬\n",
    "    m_name  : é€‰æ‹©ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹\n",
    "    u_dict  : ç”¨æˆ·è‡ªå®šä¹‰çš„åˆ†è¯è®¾ç½®ç”¨æˆ·è¯å…¸ã€‚\n",
    "    p_tag   : æ˜¯å¦è¿›è¡Œè¯æ€§æ ‡å‡†ï¼ˆæ˜¯çš„è¯ï¼Œéœ€è¦åœ¨è‡ªå®šä¹‰çš„è¯å…¸ä¸­ï¼Œä¹Ÿè¦æ·»åŠ ç›¸åº”çš„è¯æ€§ tabé”®éš”å¼€åœ¨ä¸€è¡Œ\n",
    "    \"\"\"\n",
    "    # m_name= \"news\"\n",
    "    # m_name= \"mixed\"\n",
    "    # p_tag= True # æ˜¯å¦åŒ…å«è¯æ€§\n",
    "    seg = pkuseg.pkuseg(model_name=m_name, user_dict=u_dict, postag=p_tag)           # ä»¥é»˜è®¤é…ç½®åŠ è½½æ¨¡å‹    \n",
    "    res = seg.cut(str)  # è¿›è¡Œåˆ†è¯\n",
    "   \n",
    "    return seg.cut(str)  # è¿›è¡Œåˆ†è¯\n",
    "\n",
    "#! æµ‹è¯•\n",
    "res = pkuseg_postag('æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€é¢å¯¹æš´é›¨ï¼Œè¯·æ”¶å¥½è¿™ä»½#é¿é™©ç”Ÿå­˜æŒ‡å—#ã€‘#èœ€é»å¸¦ä½ æ¶¨å§¿åŠ¿#è¿‘æ—¥æ¥ï¼Œæ²³å—ä¸¤å°æ—¶æš´é›¨è®°å½•åˆè¢«åˆ·æ–°ï¼æ¥è¿ä¸æ–­çš„ç½•è§æš´é›¨è¢­å‡»å¤šä¸ªåŸå¸‚ï¼Œç†Ÿæ‚‰çš„äº¤é€šå·¥å…·éƒ½å˜å¾—ä¸å†å®‰å…¨ï¼Œè¯¥å¦‚ä½•è¿œç¦»â€œçœ‹ä¸è§çš„å±é™©â€?é¢å¯¹æš´é›¨è¯¥å¦‚ä½•é¿é™©è„±å›°?æˆ³è§†é¢‘â†“æ”¶ä¸‹è¿™ä»½ç”Ÿå­˜æŒ‡å—ï¼å°å¤®è§†é¢‘çš„å¾®åšè§†é¢‘\n",
      "jieba:\n",
      "[('ã€', 'x'), ('é¢å¯¹', 'v'), ('æš´é›¨', 'n'), ('ï¼Œ', 'x'), ('è¯·', 'v'), ('æ”¶å¥½', 'v'), ('è¿™ä»½', 'mq'), ('#', 'x'), ('é¿é™©', 'v'), ('ç”Ÿå­˜', 'v'), ('æŒ‡å—', 'n'), ('#', 'x'), ('ã€‘', 'x'), ('#', 'x'), ('èœ€é»', 'n'), ('å¸¦', 'v'), ('ä½ ', 'r'), ('æ¶¨', 'v'), ('å§¿åŠ¿', 'n'), ('#', 'x'), ('è¿‘æ—¥æ¥', 'l'), ('ï¼Œ', 'x'), ('æ²³å—', 'ns'), ('ä¸¤', 'm'), ('å°æ—¶', 'n'), ('æš´é›¨', 'n'), ('è®°å½•', 'n'), ('åˆ', 'd'), ('è¢«', 'p'), ('åˆ·æ–°', 'v'), ('ï¼', 'x'), ('æ¥è¿ä¸æ–­', 'l'), ('çš„', 'uj'), ('ç½•è§', 'a'), ('æš´é›¨', 'n'), ('è¢­å‡»', 'v'), ('å¤šä¸ª', 'm'), ('åŸå¸‚', 'ns'), ('ï¼Œ', 'x'), ('ç†Ÿæ‚‰', 'v'), ('çš„', 'uj'), ('äº¤é€šå·¥å…·', 'l'), ('éƒ½', 'd'), ('å˜å¾—', 'v'), ('ä¸å†', 'd'), ('å®‰å…¨', 'an'), ('ï¼Œ', 'x'), ('è¯¥', 'r'), ('å¦‚ä½•', 'r'), ('è¿œç¦»', 'v'), ('â€œ', 'x'), ('çœ‹ä¸è§', 'v'), ('çš„', 'uj'), ('å±é™©', 'an'), ('â€', 'x'), ('?', 'x'), ('é¢å¯¹', 'v'), ('æš´é›¨', 'n'), ('è¯¥', 'r'), ('å¦‚ä½•', 'r'), ('é¿é™©', 'v'), ('è„±å›°', 'v'), ('?', 'x'), ('æˆ³', 'v'), ('è§†é¢‘', 'n'), ('â†“', 'x'), ('æ”¶ä¸‹', 'v'), ('è¿™ä»½', 'mq'), ('ç”Ÿå­˜', 'v'), ('æŒ‡å—', 'n'), ('ï¼', 'x'), ('å°å¤®', 'n'), ('è§†é¢‘', 'n'), ('çš„', 'uj'), ('å¾®åš', 'a'), ('è§†é¢‘', 'n')]\n",
      "pkuseg:\n",
      "[('ã€', 'nr'), ('é¢å¯¹', 'v'), ('æš´é›¨', 'n'), ('ï¼Œ', 'w'), ('è¯·', 'v'), ('æ”¶å¥½', 'v'), ('è¿™', 'r'), ('ä»½', 'q'), ('#', 'n'), ('é¿é™©', 'v'), ('ç”Ÿå­˜', 'vn'), ('æŒ‡å—', 'n'), ('#', 'v'), ('ã€‘', 'v'), ('#', 'n'), ('èœ€é»', 'nr'), ('å¸¦', 'v'), ('ä½ ', 'r'), ('æ¶¨', 'v'), ('å§¿åŠ¿', 'n'), ('#', 'v'), ('è¿‘æ—¥æ¥', 'l'), ('ï¼Œ', 'w'), ('æ²³å—', 'ns'), ('ä¸¤', 'm'), ('å°æ—¶', 'n'), ('æš´é›¨', 'n'), ('è®°å½•', 'v'), ('åˆ', 'd'), ('è¢«', 'p'), ('åˆ·æ–°', 'v'), ('ï¼', 'w'), ('æ¥è¿ä¸æ–­', 'l'), ('çš„', 'u'), ('ç½•è§', 'a'), ('æš´é›¨', 'n'), ('è¢­å‡»', 'v'), ('å¤š', 'm'), ('ä¸ª', 'q'), ('åŸå¸‚', 'n'), ('ï¼Œ', 'w'), ('ç†Ÿæ‚‰', 'v'), ('çš„', 'u'), ('äº¤é€š', 'n'), ('å·¥å…·', 'n'), ('éƒ½', 'd'), ('å˜', 'v'), ('å¾—', 'u'), ('ä¸', 'd'), ('å†', 'd'), ('å®‰å…¨', 'a'), ('ï¼Œ', 'w'), ('è¯¥', 'v'), ('å¦‚ä½•', 'r'), ('è¿œç¦»', 'v'), ('â€œ', 'w'), ('çœ‹', 'v'), ('ä¸è§', 'v'), ('çš„', 'u'), ('å±é™©', 'an'), ('â€', 'w'), ('?', 'v'), ('é¢å¯¹', 'v'), ('æš´é›¨', 'n'), ('è¯¥', 'v'), ('å¦‚ä½•', 'r'), ('é¿é™©', 'v'), ('è„±å›°', 'v'), ('?æˆ³', 'v'), ('è§†é¢‘', 'n'), ('â†“', 'v'), ('æ”¶ä¸‹', 'v'), ('è¿™', 'r'), ('ä»½', 'q'), ('ç”Ÿå­˜', 'vn'), ('æŒ‡å—', 'n'), ('ï¼', 'w'), ('å°å¤®', 'nr'), ('è§†é¢‘', 'n'), ('çš„', 'u'), ('å¾®åš', 'a'), ('è§†é¢‘', 'n')]\n"
     ]
    }
   ],
   "source": [
    "#! æµ‹è¯•\n",
    "word_str = tweets[\"å»å™ª\"][0]\n",
    "print(word_str)\n",
    "\n",
    "print(\"jieba:\")\n",
    "res = jieba_postag(word_str)\n",
    "print(res)\n",
    "\n",
    "print(\"pkuseg:\")\n",
    "res = pkuseg_postag(word_str)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   å¾®åšæ­£æ–‡         100 non-null    string\n",
      " 1   å»å™ª           100 non-null    string\n",
      " 2   jieba        100 non-null    object\n",
      " 3   pkuseg       100 non-null    object\n",
      " 4   jieba_stop   100 non-null    object\n",
      " 5   pkuseg_stop  100 non-null    object\n",
      "dtypes: object(4), string(2)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   å¾®åšæ­£æ–‡           100 non-null    string\n",
      " 1   å»å™ª             100 non-null    string\n",
      " 2   jieba          100 non-null    object\n",
      " 3   pkuseg         100 non-null    object\n",
      " 4   jieba_stop     100 non-null    object\n",
      " 5   pkuseg_stop    100 non-null    object\n",
      " 6   jieba_postag   100 non-null    object\n",
      " 7   pkuseg_postag  100 non-null    object\n",
      "dtypes: object(6), string(2)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets[\"jieba_postag\"] = tweets[\"å»å™ª\"].apply(jieba_postag)\n",
    "tweets[\"pkuseg_postag\"] = tweets[\"å»å™ª\"].apply(pkuseg_postag)\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['é¢å¯¹', 'æš´é›¨', 'æ”¶å¥½', 'è¿™ä»½', 'é¿é™©', 'ç”Ÿå­˜', 'æŒ‡å—', 'èœ€é»', 'å§¿åŠ¿', 'è¿‘æ—¥æ¥', 'å°æ—¶', 'æš´é›¨', 'è®°å½•', 'åˆ·æ–°', 'æ¥è¿ä¸æ–­', 'ç½•è§', 'æš´é›¨', 'è¢­å‡»', 'å¤šä¸ª', 'åŸå¸‚', 'ç†Ÿæ‚‰', 'äº¤é€šå·¥å…·', 'å˜å¾—', 'ä¸å†', 'å®‰å…¨', 'è¿œç¦»', 'çœ‹ä¸è§', 'å±é™©', 'é¢å¯¹', 'æš´é›¨', 'é¿é™©', 'è„±å›°', 'è§†é¢‘', 'æ”¶ä¸‹', 'è¿™ä»½', 'ç”Ÿå­˜', 'æŒ‡å—', 'å°å¤®', 'è§†é¢‘', 'å¾®åš', 'è§†é¢‘']\n"
     ]
    }
   ],
   "source": [
    "#! æµ‹è¯• å¸¦æœ‰è¯æ€§æ ‡å‡†çš„å»åœç”¨è¯\n",
    "word_ls = tweets[\"jieba_postag\"][0]\n",
    "stopword_file = \"../05stopwords/hit_stopwords.txt\"\n",
    "postag = True\n",
    "user_file = \"../05stopwords/user_stopwords.txt\"\n",
    "\n",
    "res = clear_stopword(word_ls, stopword_file, postag, user_file) # å»å™ª\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   å¾®åšæ­£æ–‡                100 non-null    string\n",
      " 1   å»å™ª                  100 non-null    string\n",
      " 2   jieba               100 non-null    object\n",
      " 3   pkuseg              100 non-null    object\n",
      " 4   jieba_stop          100 non-null    object\n",
      " 5   pkuseg_stop         100 non-null    object\n",
      " 6   jieba_postag        100 non-null    object\n",
      " 7   pkuseg_postag       100 non-null    object\n",
      " 8   jieba_postag_stop   100 non-null    object\n",
      " 9   pkuseg_postag_stop  100 non-null    object\n",
      "dtypes: object(8), string(2)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "stopword_file = \"../05stopwords/hit_stopwords.txt\"\n",
    "postag = True\n",
    "user_file = \"../05stopwords/user_stopwords.txt\"\n",
    "\n",
    "tweets[\"jieba_postag_stop\"] = tweets[\"jieba_postag\"].apply(clear_stopword, args=[stopword_file, postag, user_file])\n",
    "tweets[\"pkuseg_postag_stop\"] = tweets[\"pkuseg_postag\"].apply(clear_stopword, args=[stopword_file, postag, user_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   å¾®åšæ­£æ–‡                100 non-null    string\n",
      " 1   å»å™ª                  100 non-null    string\n",
      " 2   jieba               100 non-null    object\n",
      " 3   pkuseg              100 non-null    object\n",
      " 4   jieba_stop          100 non-null    object\n",
      " 5   pkuseg_stop         100 non-null    object\n",
      " 6   jieba_postag        100 non-null    object\n",
      " 7   pkuseg_postag       100 non-null    object\n",
      " 8   jieba_postag_stop   100 non-null    object\n",
      " 9   pkuseg_postag_stop  100 non-null    object\n",
      "dtypes: object(8), string(2)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.to_excel(\"../02Data/jieba_pkuseg.xlsx\")\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 æ–‡æœ¬å»é‡ ã€è€ƒè™‘å‘è¡¨çš„ç”¨æˆ·ï¼Œ**å®˜æ–¹å·**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 æ–‡æœ¬æ ‡è®°\n",
    "\n",
    "- æ‰‹åŠ¨æ•´ç†æ ‡è®°ï¼Œæ¨¡å‹è¾“å…¥æ•°æ®\n",
    "\n",
    "- ä¸»é¢˜å»ºæ¨¡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 ç‰¹å¾è¯é€‰æ‹©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç§»åŠ¨ å…±äº« ï¼Œ å…±äº« æ±½è½¦ ï¼Œ å…±äº« ç»æµ ï¼Œ å…±äº« å•è½¦\n",
      "è´¢ç» æ ç›® ï¼Œ è´¢ç» æ”¿ç­– ï¼Œ ç»æµ æ”¿ç­– ï¼Œ å…±äº« ç»æµ\n",
      "+++++ä½¿ç”¨ CountVectorizer\n",
      "  (0, 5)\t1\n",
      "  (0, 0)\t4\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 6)\t2\n",
      "  (1, 7)\t2\n",
      "  (1, 3)\t1\n",
      "  (1, 2)\t2\n",
      "['å…±äº«' 'å•è½¦' 'æ”¿ç­–' 'æ ç›®' 'æ±½è½¦' 'ç§»åŠ¨' 'ç»æµ' 'è´¢ç»']\n",
      "[[4 1 0 0 1 1 1 0]\n",
      " [1 0 2 1 0 0 2 2]]\n",
      "   å…±äº«  å•è½¦  æ”¿ç­–  æ ç›®  æ±½è½¦  ç§»åŠ¨  ç»æµ  è´¢ç»\n",
      "0   4   1   0   0   1   1   1   0\n",
      "1   1   0   2   1   0   0   2   2\n",
      "+++++ä½¿ç”¨ TfidfVectorizer\n",
      "  (0, 1)\t0.2935323404273021\n",
      "  (0, 6)\t0.20885067778197156\n",
      "  (0, 4)\t0.2935323404273021\n",
      "  (0, 0)\t0.8354027111278862\n",
      "  (0, 5)\t0.2935323404273021\n",
      "  (1, 2)\t0.5889689090267317\n",
      "  (1, 3)\t0.29448445451336586\n",
      "  (1, 7)\t0.5889689090267317\n",
      "  (1, 6)\t0.41905622959186595\n",
      "  (1, 0)\t0.20952811479593297\n",
      "['å…±äº«' 'å•è½¦' 'æ”¿ç­–' 'æ ç›®' 'æ±½è½¦' 'ç§»åŠ¨' 'ç»æµ' 'è´¢ç»']\n",
      "[[0.83540271 0.29353234 0.         0.         0.29353234 0.29353234\n",
      "  0.20885068 0.        ]\n",
      " [0.20952811 0.         0.58896891 0.29448445 0.         0.\n",
      "  0.41905623 0.58896891]]\n",
      "         å…±äº«        å•è½¦        æ”¿ç­–        æ ç›®        æ±½è½¦        ç§»åŠ¨        ç»æµ  \\\n",
      "0  0.835403  0.293532  0.000000  0.000000  0.293532  0.293532  0.208851   \n",
      "1  0.209528  0.000000  0.588969  0.294484  0.000000  0.000000  0.419056   \n",
      "\n",
      "         è´¢ç»  \n",
      "0  0.000000  \n",
      "1  0.588969  \n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•å­¦ä¹ \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import jieba\n",
    "\n",
    "data=[\"ç§»åŠ¨å…±äº«ï¼Œå…±äº«æ±½è½¦ï¼Œå…±äº«ç»æµï¼Œå…±äº«å•è½¦\",\n",
    "     \"è´¢ç»æ ç›®ï¼Œè´¢ç»æ”¿ç­–ï¼Œç»æµæ”¿ç­–ï¼Œå…±äº«ç»æµ\"] \n",
    "\n",
    "# éœ€è¦æå‰åˆ†è¯\n",
    "\n",
    "# åˆ†è¯\n",
    "cut_data=[]\n",
    "for s in data:\n",
    "    cut_s = jieba.cut(s)\n",
    "    l_cut_s=' '.join(list(cut_s))    \n",
    "    cut_data.append(l_cut_s)\n",
    "    print(l_cut_s)\n",
    "    \n",
    "# ä½¿ç”¨ CountVectorizer\n",
    "print(\"+++++ä½¿ç”¨ CountVectorizer\")\n",
    "transfer = CountVectorizer(stop_words=[\"æ‰“ç®—\",\"å°±æ˜¯\"]) \n",
    "#å®ä¾‹åŒ–ä¸€ä¸ªè½¬æ¢å™¨ç±»,\n",
    "# # stop_words=[\"æ‰“ç®—\",\"å°±æ˜¯\"],å»é™¤ä¸æƒ³è¦çš„è¯\n",
    "data_new = transfer.fit_transform(cut_data)  #è°ƒç”¨fit_transform()\n",
    "print(data_new)\n",
    "print(transfer.get_feature_names_out())\n",
    "print(data_new.toarray()) \n",
    "#æ„å»ºæˆä¸€ä¸ªäºŒç»´è¡¨ï¼š\n",
    "df=pd.DataFrame(data_new.toarray(),columns=transfer.get_feature_names_out())\n",
    "print(df)   \n",
    "\n",
    "# ä½¿ç”¨ TfidfVectorizer\n",
    "print(\"+++++ä½¿ç”¨ TfidfVectorizer\")\n",
    "transfer = TfidfVectorizer() #å®ä¾‹åŒ–ä¸€ä¸ªè½¬æ¢å™¨ç±»\n",
    "data_new = transfer.fit_transform(cut_data) #è°ƒç”¨fit_transform()\n",
    "print(data_new)\n",
    "print(transfer.get_feature_names_out())\n",
    "print(data_new.toarray()) \n",
    "#æ„å»ºæˆä¸€ä¸ªäºŒç»´è¡¨ï¼š\n",
    "df=pd.DataFrame(data_new.toarray(),columns=transfer.get_feature_names_out())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨å°è£…\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def word2vec(lsls, v_type):\n",
    "    ls_str=[]\n",
    "    for s in lsls:\n",
    "        strs = ' '.join(s) \n",
    "        ls_str.append(strs)\n",
    "    \n",
    "    if v_type == \"TFIDF\":\n",
    "    # TF-IDF(term frequencyâ€”inverse document frequency)\n",
    "        transfer = TfidfVectorizer() #å®ä¾‹åŒ–ä¸€ä¸ªè½¬æ¢å™¨ç±»\n",
    "    else:\n",
    "        transfer = CountVectorizer()\n",
    "    data_new = transfer.fit_transform(ls_str) #è°ƒç”¨fit_transform()\n",
    "    #æ„å»ºæˆä¸€ä¸ªäºŒç»´è¡¨ï¼š\n",
    "    df=pd.DataFrame(data_new.toarray(), columns=transfer.get_feature_names_out())\n",
    "    \n",
    "    withWeight = transfer.vocabulary_\n",
    "    return df, withWeight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e481c8094450a362835654784466fc3605d9d17b45d80f6ff62525ad7933ac54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
